sigma[1,1] <- sd_beta_0 * sd_beta_0
sigma[2,2] <- sd_beta_1 * sd_beta_1
sigma[1,2] <- sd_beta_0 * rho * sd_beta_1
sigma[2,1] <- sigma[1,2]
pre[1:2,1:2] <- inverse(sigma[1:2,1:2])
}
")
data_list <- list(
Nobs = nrow(mydata),
subject = mydata$ID,
N = length(unique(mydata$ID)),
y = mydata$y_it,
x = mydata$x_it
)
jags_text <- paste0("
model {
# likelihood ------------------------------
for (j in 1:Nobs) {
y[j] ~ dnorm(y_mu[j], y_pre)
y_mu[j] <- mu[subject[j]] + phi[subject[j]] * x[j]
}
for (i in 1:N) {
mu[i]  <- raneff[i,1]
phi[i] <- raneff[i,2]
raneff[i,1:2] ~ dmnorm(beta[1:2], pre[1:2,1:2])
}
# priors ---------------------------------
y_pre ~ dgamma(0.001, 0.001)
log_pre <- log(y_pre)
beta[1] ~ dnorm(0, 0.01)  # precision=0.01, variance=100
beta[2] ~ dnorm(0, 0.01)
beta_0 <- beta[1]
beta_1 <- beta[2]
tau_beta_0 ~ dgamma(0.001, 0.001)
sd_beta_0 <- sqrt(1/tau_beta_0)
log_tau_beta_0 <- log(tau_beta_0)
tau_beta_1 ~ dgamma(0.001, 0.001)
sd_beta_1 <- sqrt(1/tau_beta_1)
log_tau_beta_1 <- log(tau_beta_1)
rho ~ dunif(-1, 1)
prho <- (rho + 1) / 2
logit_rho <- log(prho / (1 - prho))
sigma[1,1] <- sd_beta_0 * sd_beta_0
sigma[2,2] <- sd_beta_1 * sd_beta_1
sigma[1,2] <- sd_beta_0 * rho * sd_beta_1
sigma[2,1] <- sigma[1,2]
pre[1:2,1:2] <- inverse(sigma[1:2,1:2])
}
")
data_list <- list(
Nobs = nrow(mydata),
subject = mydata$ID,
N = length(unique(mydata$ID)),
y = mydata$y_it,
x = mydata$x_it
)
jags_file <- textConnection(jags_text)
jags_model <- jags.model(jags_file,
data = data_list,
n.chain = 4)
update(jags_model, 5000)
variables <- c("mu", "phi", "beta_0", "beta_1",
"log_pre", "log_tau_beta_0", "log_tau_beta_1", "logit_rho",
"y_pre", "tau_beta_0", "tau_beta_1", "rho")
post <- coda.samples(jags_model,
variable.names = variables,
n.iter = 25000, thin = 10)
samps <- do.call(rbind, post)
View(samps)
source("posterior_summary.R")
source("posterior_summary.R")
set.seed(123)
Nnum <- 500 # number of level 2 units
Tnum <- 50  # number of level 1 units
beta <- c(0, 0.3)
rho <- 0.3
u_cov <- sqrt(1)*sqrt(0.09)*rho
u_sigma <- matrix(c(1, u_cov, u_cov, 0.09), nrow = 2)
bdata <- mvrnorm(Nnum, mu = beta, Sigma = u_sigma)
bdata <- as.data.frame(bdata)
names(bdata) <- c("mu", "phi")
bdata$ID <- c(1:Nnum)
mydata <- data.frame(matrix(NA, nrow = Nnum*Tnum, ncol = 2))
names(mydata) <- c("ID", "t")
mydata$ID <- rep(1:Nnum, each = Tnum)
mydata$t <- rep(1:Tnum, Nnum)
mydata$e_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 0.1)
mydata$x_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 1)
mydata <- left_join(mydata, bdata[, c("ID", "mu","phi")], by = "ID")
mydata$y_it <- mydata$mu + mydata$x_it*mydata$phi + mydata$e_it
result <- summarize_posterior(post)
View(result)
max(result$RHAT)
library(("blvmeval"))
library("blvmeval")
raneff_mu_list <- vector("list", Nnum)
raneff_cov_list <- vector("list", Nnum)
for (i in 1:Nnum) {
raneff_mu_list[[i]] <- c(
mean(samps[, paste0("mu[", i, "]")]),
mean(samps[, paste0("phi[", i, "]")])
)
raneff_cov_list[[i]] <- cov(samps[, c(paste0("mu[", i, "]"), paste0("phi[", i, "]"))])
}
View(raneff_mu_list)
View(raneff_cov_list)
# specify the function that computes the log joint probability for each unit
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# conditional likelihood
Nobs <- data$Nobs
Nnum <- data$N
Tnum <- Nobs/Nnum
y_i <- data$y[((i-1)*Tnum+1):(i*Tnum)]
x_i <- data$x[((i-1)*Tnum+1):(i*Tnum)]
predicted_y <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_t_i <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_i <- numeric(Ngrid*Ngrid) # log likelihood for all observations for person i, for each quadrature point
x_i_extended <- rep(x_i, times = Ngrid * Ngrid)
x_i_extended_mat <- matrix(x_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
y_i_extended <- rep(y_i, times = Ngrid * Ngrid)
y_i_extended_mat <- matrix(y_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
# Compute log conditional likelihood for each unit
predicted_y <- nodes[, 1] + nodes[, 2] * x_i_extended_mat
log_con_t_i <- dnorm(y_i_extended_mat, mean = predicted_y, sd = 1/sqrt(samples_s[["y_pre"]]), log = TRUE)
log_con_i <- rowSums(log_con_t_i)
# Compute log prior probability for latent variables (random effects)
raneff_i <- numeric(Ngrid*Ngrid)
sd_mu <- sqrt(1/samples_s[["tau_beta_0"]])
sd_phi <- sqrt(1/samples_s[["tau_beta_1"]])
mean <- c(samples_s[["beta_0"]], samples_s[["beta_1"]])
sigma <- matrix(c(sd_mu^2, sd_mu*samples_s[["rho"]]*sd_phi,
sd_mu*samples_s[["rho"]]*sd_phi, sd_phi^2), nrow = 2)
log_raneff_i <- mvtnorm::dmvnorm(nodes, mean, sigma, log = TRUE)
# Return the log joint probability for each unit
log_raneff_i + log_con_i
}
log_lik_result <- blvmeval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
blvmeval::calc_IC(log_lik_result, 1)
library(blvmeval)
library(bleval)
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/blvmeval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
library(bleval)
log_lik_result <- blvmeval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
# specify the function that computes the log joint probability for each unit
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# conditional likelihood
Nobs <- data$Nobs
Nnum <- data$N
Tnum <- Nobs/Nnum
y_i <- data$y[((i-1)*Tnum+1):(i*Tnum)]
x_i <- data$x[((i-1)*Tnum+1):(i*Tnum)]
predicted_y <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_t_i <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_i <- numeric(Ngrid*Ngrid) # log likelihood for all observations for person i, for each quadrature point
x_i_extended <- rep(x_i, times = Ngrid * Ngrid)
x_i_extended_mat <- matrix(x_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
y_i_extended <- rep(y_i, times = Ngrid * Ngrid)
y_i_extended_mat <- matrix(y_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
# Compute log conditional likelihood for each unit
predicted_y <- nodes[, 1] + nodes[, 2] * x_i_extended_mat
log_con_t_i <- dnorm(y_i_extended_mat, mean = predicted_y, sd = 1/sqrt(samples_s[["y_pre"]]), log = TRUE)
log_con_i <- rowSums(log_con_t_i)
# Compute log prior probability for latent variables (random effects)
raneff_i <- numeric(Ngrid*Ngrid)
sd_mu <- sqrt(1/samples_s[["tau_beta_0"]])
sd_phi <- sqrt(1/samples_s[["tau_beta_1"]])
mean <- c(samples_s[["beta_0"]], samples_s[["beta_1"]])
sigma <- matrix(c(sd_mu^2, sd_mu*samples_s[["rho"]]*sd_phi,
sd_mu*samples_s[["rho"]]*sd_phi, sd_phi^2), nrow = 2)
log_raneff_i <- mvtnorm::dmvnorm(nodes, mean, sigma, log = TRUE)
# Return the log joint probability for each unit
log_raneff_i + log_con_i
}
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
library(bleval)
save.image("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval/example/0314.RData")
unloadNamespace("bleval")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
remove.packages("blvmeval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
unloadNamespace("bleval")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
bleval::calc_IC(log_lik_result, 1)
summary(post)
View(result)
dim(samps)
remove.packages("blvmeval", lib = "D:/Software/R/R-4.2.2/library")
knitr::opts_chunk$set(echo = TRUE)
data(example1_LMSEM, package = "bleval")
knitr::opts_chunk$set(echo = TRUE)
library(bleval, lib.loc = "D:/Software/R/R-4.2.2/library")
data(example1_LMSEM, package = "bleval")
data(example1, package = "bleval")
data(example1_LMSEM, package = "bleval")
library(bleval, lib.loc = "D:/Software/R/R-4.2.2/library") # load the package
data(example1_LMSEM, package = "bleval")
# Manually install the bleval package from a local `.tar.gz` file
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
# Manually install the bleval package from a local `.tar.gz` file
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
unloadNamespace("bleval")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
# Manually install the bleval package from a local `.tar.gz` file
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
# Load the package
library(bleval, lib.loc = "D:/Software/R/R-4.2.2/library")
data(example1_LMSEM, package = "bleval")
View(example1_LMSEM)
View(example1_LMSEM)
example1_LMSEM <- scale(example1_LMSEM)
?scale
library(rjags)
library(rjags)
library(rjags)
install.packages("coda")
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(rjags)
model_string <- "
model {
# Measurement Models --------------------
for (i in 1:N) {
for (j in 1:NumX) {
X[i, j] ~ dnorm(mu_X[i, j], tau_X[j])
mu_X[i, j] <- lambdaX[j] * eta_X[i]
}
for (j in 1:NumM) {
M[i, j] ~ dnorm(mu_M[i, j], tau_M[j])
mu_M[i, j] <- lambdaM[j] * eta_M[i]
}
for (j in 1:NumY) {
Y[i, j] ~ dnorm(mu_Y[i, j], tau_Y[j])
mu_Y[i, j] <- lambdaY[j] * eta_Y[i]
}
}
# Latent Variables ----------------------
for (i in 1:N) {
eta_X[i] ~ dnorm(0, tau_eta_X)
eta_M[i] ~ dnorm(0, tau_eta_M)
eta_Y[i] ~ dnorm(mu_eta_Y[i], tau_eta_Y)
}
# Interaction term ----------------------
for (i in 1:N) {
eta_XM[i] <- eta_X[i] * eta_M[i]
}
# Structural Model ----------------------
for (i in 1:N) {
mu_eta_Y[i] <- b1 * eta_X[i] + b2 * eta_M[i] + b3 * eta_XM[i]
}
# Priors --------------------------------
b1 ~ dnorm(0, 0.01)
b2 ~ dnorm(0, 0.01)
b3 ~ dnorm(0, 0.01)
lambdaX[1] <- 1
for (j in 2:NumX) {
lambdaX[j] ~ dnorm(0, 0.01)
}
lambdaM[1] <- 1
for (j in 2:NumM) {
lambdaM[j] ~ dnorm(0, 0.01)
}
lambdaY[1] <- 1
for (j in 2:NumY) {
lambdaY[j] ~ dnorm(0, 0.01)
}
for (j in 1:NumX) {
tau_X[j] ~ dgamma(0.001, 0.001)
}
for (j in 1:NumM) {
tau_M[j] ~ dgamma(0.001, 0.001)
}
for (j in 1:NumY) {
tau_Y[j] ~ dgamma(0.001, 0.001)
}
tau_eta_X ~ dgamma(0.001, 0.001)
tau_eta_M ~ dgamma(0.001, 0.001)
tau_eta_Y ~ dgamma(0.001, 0.001)
}
"
data_list <- list(
X = example1_LMSEM[, 14:18],  # X1-X5
M = example1_LMSEM[, 10:13],  # M1-M4
Y = example1_LMSEM[, 1:9],    # Y1-Y9
N = nrow(example1_LMSEM),     # sample size
NumX = 5,                     # number of indicators for X
NumM = 4,                     # number of indicators for M
NumY = 9                      # number of indicators for Y
)
jags_model <- jags.model(textConnection(model_string), data = data_list, n.chains = 4)
update(jags_model, 5000)
post <- coda.samples(jags_model,
c("b1", "b2", "b3", "lambdaX", "lambdaM", "lambdaY",
"tau_X", "tau_M", "tau_Y",
"tau_eta_X", "tau_eta_M", "tau_eta_Y",
"eta_X", "eta_M", "eta_XM", "eta_Y"),
n.iter = 25000, thin = 10)
samps <- do.call(rbind, post)
dim(samps)
source("posterior_summary.R")
result <- summarize_posterior(post)
max(result$RHAT)
View(result)
max(result$RHAT[-c("lambdaM[1]")])
max(subset(result, !(rownames(result) %in% c("lambdaM[1]", "lambdaX[1]", "lambdaY[1]")))$RHAT)
# posterior draws for model parameters only
pars_vector <- c("b1", "b2", "b3",
"lambdaX[2]","lambdaX[3]","lambdaX[4]","lambdaX[5]",
"lambdaM[2]","lambdaM[3]","lambdaM[4]",
"lambdaY[2]","lambdaY[3]","lambdaY[4]","lambdaY[5]",
"lambdaY[6]","lambdaY[7]","lambdaY[8]","lambdaY[9]",
"tau_X[1]", "tau_X[2]","tau_X[3]","tau_X[4]","tau_X[5]",
"tau_M[1]","tau_M[2]","tau_M[3]","tau_M[4]",
"tau_Y[1]","tau_Y[2]","tau_Y[3]","tau_Y[4]","tau_Y[5]",
"tau_Y[6]","tau_Y[7]","tau_Y[8]","tau_Y[9]",
"tau_eta_X", "tau_eta_M", "tau_eta_Y")
samps2 <- as.matrix(samps[ ,pars_vector])
dim(samps2)
dim(samps)
dim(samps2)
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# conditional likelihood
X_i <- data$X[i,]
M_i <- data$M[i,]
Y_i <- data$Y[i,]
Ndim <- 3
log_con_X_i <- matrix(NA, nrow = Ngrid^Ndim, ncol = data$NumX)
log_con_M_i <- matrix(NA, nrow = Ngrid^Ndim, ncol = data$NumM)
log_con_Y_i <- matrix(NA, nrow = Ngrid^Ndim, ncol = data$NumY)
predicted_Y <- matrix(NA, nrow = Ngrid^Ndim, ncol = data$NumY)
log_con_i <- numeric(Ngrid^Ndim) # log conditional likelihood for person i
X_i_extended <- rep(X_i, times = Ngrid^Ndim)
X_i_extended_mat <- matrix(X_i_extended, nrow = Ngrid^Ndim, ncol = data$NumX, byrow = TRUE)
M_i_extended <- rep(M_i, times = Ngrid^Ndim)
M_i_extended_mat <- matrix(M_i_extended, nrow = Ngrid^Ndim, ncol = data$NumM, byrow = TRUE)
Y_i_extended <- rep(Y_i, times = Ngrid^Ndim)
Y_i_extended_mat <- matrix(Y_i_extended, nrow = Ngrid^Ndim, ncol = data$NumY, byrow = TRUE)
lambdaX <- as.vector(samples_s[grep("^lambdaX\\[\\d+\\]$", names(samples_s))])
lambdaX <- c(1, lambdaX)
sdX_matrix <- matrix(rep( sqrt(1/samples_s[grep("^tau_X\\[\\d+\\]$", names(samples_s))]), times = Ngrid^Ndim), nrow = Ngrid^Ndim, byrow = TRUE)
log_con_X_i <- dnorm(X_i_extended_mat, mean = nodes[,1] %*% t(lambdaX), sd = sdX_matrix, log = TRUE)
lambdaM <- as.vector(samples_s[grep("^lambdaM\\[\\d+\\]$", names(samples_s))])
lambdaM <- c(1, lambdaM)
sdM_matrix <- matrix(rep( sqrt(1/samples_s[grep("^tau_M\\[\\d+\\]$", names(samples_s))]), times = Ngrid^Ndim), nrow = Ngrid^Ndim, byrow = TRUE)
log_con_M_i <- dnorm(M_i_extended_mat, mean = nodes[,2] %*% t(lambdaM), sd = sdM_matrix, log = TRUE)
lambdaY <- as.vector(samples_s[grep("^lambdaY\\[\\d+\\]$", names(samples_s))])
lambdaY <- c(1, lambdaY)
sdY_matrix <- matrix(rep( sqrt(1/samples_s[grep("^tau_Y\\[\\d+\\]$", names(samples_s))]), times = Ngrid^Ndim), nrow = Ngrid^Ndim, byrow = TRUE)
log_con_Y_i <- dnorm(Y_i_extended_mat, mean = nodes[,3] %*% t(lambdaY), sd = sdY_matrix, log = TRUE)
log_con_i <- rowSums(log_con_X_i) + rowSums(log_con_M_i) + rowSums(log_con_Y_i)
# random effects
log_etaX_i <- numeric(Ngrid^Ndim)
log_etaM_i <- numeric(Ngrid^Ndim)
log_etaY_i <- numeric(Ngrid^Ndim)
predicted_Y <- samples_s[["b1"]]*nodes[,1] + samples_s[["b2"]]*nodes[,2] + samples_s[["b3"]]*nodes[,1]*nodes[,2]
log_etaX_i <- dnorm(nodes[,1], mean = 0, sd = sqrt(1/samples_s[["tau_eta_X"]]), log = TRUE)
log_etaM_i <- dnorm(nodes[,2], mean = 0, sd = sqrt(1/samples_s[["tau_eta_M"]]), log = TRUE)
log_etaY_i <- dnorm(nodes[,3], mean = predicted_Y, sd = sqrt(1/samples_s[["tau_eta_Y"]]), log = TRUE)
# return
log_con_i + (log_etaX_i + log_etaM_i + log_etaY_i)
}
# Create lists to store posterior means and covariance matrices of random effects
Nnum <- nrow(example1_LMSEM)
raneff_mu_list <- vector("list", Nnum)
raneff_cov_list <- vector("list", Nnum)
for (i in 1:Nnum) {
# Compute the posterior mean of the random intercept and slope for unit i
raneff_mu_list[[i]] <- c(
mean(samps[, paste0("eta_X[", i, "]")]),
mean(samps[, paste0("eta_M[", i, "]")]),
mean(samps[, paste0("eta_Y[", i, "]")])
)
# Compute the posterior covariance matrix of the random intercept and slope for unit i
raneff_cov_list[[i]] <- cov(samps[, c(paste0("eta_X[", i, "]"),
paste0("eta_M[", i, "]"), paste0("eta_Y[", i, "]"))])
}
log_lik_result <- blvmeval::log_lik(samples = samps2, data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, n_cores = 3)
log_lik_result <- bleval::log_lik(samples = samps2, data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, n_cores = 3)
bleval::calc_IC(log_lik_result, 1)
log_prior <- function(samples_s) {
log_prob <- 0
norm_params <- c("b1", "b2", "b3",
paste0("lambdaX[", 2:data$NumX, "]"),
paste0("lambdaM[", 2:data$NumM, "]"),
paste0("lambdaY[", 2:data$NumY, "]"))
log_prob <- log_prob + sum(sapply(norm_params, function(param) {
dnorm(samples_s[[param]], mean = 0, sd = sqrt(1/0.01), log = TRUE)
}))
gamma_params <- c(paste0("tau_X[", 1:data$NumX, "]"),
paste0("tau_M[", 1:data$NumM, "]"),
paste0("tau_Y[", 1:data$NumY, "]"),
"tau_eta_X", "tau_eta_M", "tau_eta_Y")
log_prob <- log_prob + sum(sapply(gamma_params, function(param) {
dgamma(samples_s[[param]], shape = 0.001, rate = 0.001, log = TRUE)
}))
# return
log_prob
}
lb <- c(rep(-Inf, 18), rep(0, 21))
ub <- c(rep( Inf, 18), rep(Inf, 21))
names(lb) <- pars_vector
names(ub) <- pars_vector
blvmeval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
bleval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
bleval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
data_list <- list(
X = example1_LMSEM[, 14:18],  # Observed indicators for latent variable X
M = example1_LMSEM[, 10:13],  # Observed indicators for latent variable M
Y = example1_LMSEM[, 1:9],    # Observed indicators for latent variable Y
N = nrow(example1_LMSEM),     # Sample size (Number of units)
NumX = 5,                     # Number of indicators for latent variable X
NumM = 4,                     # Number of indicators for latent variable M
NumY = 9                      # Number of indicators for latent variable Y
)
bleval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
View(data_list)
str(data_list)
lb <- c(rep(-Inf, 18), rep(0, 21))
ub <- c(rep( Inf, 18), rep(Inf, 21))
names(lb) <- pars_vector
names(ub) <- pars_vector
data_list
bleval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
log_prior <- function(samples_s) {
log_prob <- 0
norm_params <- c("b1", "b2", "b3",
paste0("lambdaX[", 2:5, "]"),
paste0("lambdaM[", 2:4, "]"),
paste0("lambdaY[", 2:9, "]"))
log_prob <- log_prob + sum(sapply(norm_params, function(param) {
dnorm(samples_s[[param]], mean = 0, sd = sqrt(1/0.01), log = TRUE)
}))
gamma_params <- c(paste0("tau_X[", 1:5, "]"),
paste0("tau_M[", 1:4, "]"),
paste0("tau_Y[", 1:9, "]"),
"tau_eta_X", "tau_eta_M", "tau_eta_Y")
log_prob <- log_prob + sum(sapply(gamma_params, function(param) {
dgamma(samples_s[[param]], shape = 0.001, rate = 0.001, log = TRUE)
}))
# return
log_prob
}
lb <- c(rep(-Inf, 18), rep(0, 21))
ub <- c(rep( Inf, 18), rep(Inf, 21))
names(lb) <- pars_vector
names(ub) <- pars_vector
bleval::log_marg_lik(samples = samps2,
data = data_list, Ngrid = 5,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i, log_prior = log_prior,
lb = lb, ub = ub)
remove.packages("bridgesampling")
remove.packages("coda")
remove.packages("bridgesampling", lib = "D:/Software/R/R-4.2.2/library")
remove.packages("coda", lib = "D:/Software/R/R-4.2.2/library")
install.packages("coda", lib = "D:/Software/R/R-4.2.2/library")
install.packages("bridgesampling",lib = "D:/Software/R/R-4.2.2/library")
