library(MASS)
library(dplyr)
library(rjags)
library(bridgesampling)
library(mvtnorm)
library(extraDistr)
library(statmod)       # For gauss.quad.prob()
library(matrixStats)   # For logSumExp()
library(doParallel)
library(loo)
source("posterior_summary.R")
set.seed(123)
Nnum <- 500
Tnum <- 50
raneff_gamma <- c(0, 0.3)
raneff_cov <- sqrt(1)*sqrt(0.09)*0.3
raneff_Sigma <- matrix(c(1, raneff_cov, raneff_cov, 0.09), nrow = 2)
solve(raneff_Sigma)
bdata <- mvrnorm(Nnum, mu = raneff_gamma, Sigma = raneff_Sigma)
bdata <- as.data.frame(bdata)
names(bdata) <- c("mu_i", "phi_i")
bdata$ID <- c(1:Nnum)
mydata <- data.frame(matrix(NA, nrow = Nnum*Tnum, ncol = 2))
names(mydata) <- c("ID", "t")
mydata$ID <- rep(1:Nnum, each = Tnum)
mydata$t <- rep(1:Tnum, Nnum)
mydata$e_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 0.1)
mydata$x_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 1)
mydata <- left_join(mydata, bdata[, c("ID", "phi_i","mu_i")], by = "ID")
mydata$y_it <- mydata$mu_i + mydata$x_it*mydata$phi_i + mydata$e_it
summary(bdata)
summary(mydata)
bdata <- mvrnorm(Nnum, mu = beta, sigma = u_sigma)
Nnum <- 500 # number of level 2 units
Tnum <- 50  # number of level 1 units
beta <- c(0, 0.3)
rho <- 0.3
u_cov <- sqrt(1)*sqrt(0.09)*rho
u_sigma <- matrix(c(1, u_cov, u_cov, 0.09), nrow = 2)
bdata <- mvrnorm(Nnum, mu = beta, sigma = u_sigma)
?mvrnorm
set.seed(123)
N2num <- 500 # number of level 2 units
N1num <- 50  # number of level 1 units
beta <- c(0, 0.3)
rho <- 0.3
u_cov <- sqrt(1)*sqrt(0.09)*rho
u_sigma <- matrix(c(1, u_cov, u_cov, 0.09), nrow = 2)
bdata <- mvrnorm(N2num, mu = beta, Sigma = u_sigma)
bdata <- as.data.frame(bdata)
names(bdata) <- c("beta_0", "beta_1")
bdata$ID <- c(1:N2num)
mydata <- data.frame(matrix(NA, nrow = N2num*N1num, ncol = 2))
names(mydata) <- c("ID", "t")
mydata$ID <- rep(1:N2num, each = N1num)
mydata$t <- rep(1:N1num, N2num)
mydata$e_it <- rnorm(n = N2num*N1num, mean = 0, sd = 0.1)
mydata$x_it <- rnorm(n = N2num*N1num, mean = 0, sd = 1)
mydata <- left_join(mydata, bdata[, c("ID", "beta_0","beta_1")], by = "ID")
mydata$y_it <- mydata$beta_0 + mydata$x_it*mydata$beta_1 + mydata$e_it
summary(bdata)
summary(mydata)
set.seed(123)
N2num <- 500 # number of level 2 units
N1num <- 50  # number of level 1 units
beta <- c(0, 0.3)
rho <- 0.3
u_cov <- sqrt(1)*sqrt(0.09)*rho
u_sigma <- matrix(c(1, u_cov, u_cov, 0.09), nrow = 2)
bdata <- mvrnorm(N2num, mu = beta, Sigma = u_sigma)
bdata <- as.data.frame(bdata)
names(bdata) <- c("mu", "phi")
bdata$ID <- c(1:N2num)
mydata <- data.frame(matrix(NA, nrow = N2num*N1num, ncol = 2))
names(mydata) <- c("ID", "t")
mydata$ID <- rep(1:N2num, each = N1num)
mydata$t <- rep(1:N1num, N2num)
mydata$e_it <- rnorm(n = N2num*N1num, mean = 0, sd = 0.1)
mydata$x_it <- rnorm(n = N2num*N1num, mean = 0, sd = 1)
mydata <- left_join(mydata, bdata[, c("ID", "mu","phi")], by = "ID")
mydata$y_it <- mydata$mu + mydata$x_it*mydata$phi + mydata$e_it
summary(bdata)
summary(mydata)
jags_text <- paste0("
model {
# likelihood ------------------------------
for (j in 1:Nobs) {
y[j] ~ dnorm(y_mu[j], y_pre)
y_mu[j] <- mu[subject[j]] + phi[subject[j]] * x[j]
}
for (i in 1:Nnum) {
mu[i]  <- raneff[i,1]
phi[i] <- raneff[i,2]
raneff[i,1:2] ~ dmnorm(beta[1:2], pre[1:2,1:2])
}
# priors ---------------------------------
y_pre ~ dgamma(0.001, 0.001)
log_pre <- log(y_pre)
beta[1] ~ dnorm(0, 0.01)  # precision=0.01, variance=100
beta[2] ~ dnorm(0, 0.01)
beta_0 <- beta[1]
beta_1 <- beta[2]
tau_beta_0 ~ dgamma(0.001, 0.001)
sd_beta_0 <- sqrt(1/tau_beta_0)
log_tau_beta_0 <- log(tau_beta_0)
tau_beta_1 ~ dgamma(0.001, 0.001)
sd_beta_1 <- sqrt(1/tau_beta_1)
log_tau_beta_1 <- log(tau_beta_1)
rho ~ dunif(-1, 1)
prho <- (rho + 1) / 2
logit_rho <- log(prho / (1 - prho))
sigma[1,1] <- sd_beta_0 * sd_beta_0
sigma[2,2] <- sd_beta_1 * sd_beta_1
sigma[1,2] <- sd_beta_0 * rho * sd_beta_1
sigma[2,1] <- sigma[1,2]
pre[1:2,1:2] <- inverse(sigma[1:2,1:2])
}
")
data_list <- list(
Nobs = nrow(mydata),
subject = mydata$ID,
N = length(unique(mydata$ID)),
y = mydata$y_it,
x = mydata$x_it
)
jags_text <- paste0("
model {
# likelihood ------------------------------
for (j in 1:Nobs) {
y[j] ~ dnorm(y_mu[j], y_pre)
y_mu[j] <- mu[subject[j]] + phi[subject[j]] * x[j]
}
for (i in 1:N) {
mu[i]  <- raneff[i,1]
phi[i] <- raneff[i,2]
raneff[i,1:2] ~ dmnorm(beta[1:2], pre[1:2,1:2])
}
# priors ---------------------------------
y_pre ~ dgamma(0.001, 0.001)
log_pre <- log(y_pre)
beta[1] ~ dnorm(0, 0.01)  # precision=0.01, variance=100
beta[2] ~ dnorm(0, 0.01)
beta_0 <- beta[1]
beta_1 <- beta[2]
tau_beta_0 ~ dgamma(0.001, 0.001)
sd_beta_0 <- sqrt(1/tau_beta_0)
log_tau_beta_0 <- log(tau_beta_0)
tau_beta_1 ~ dgamma(0.001, 0.001)
sd_beta_1 <- sqrt(1/tau_beta_1)
log_tau_beta_1 <- log(tau_beta_1)
rho ~ dunif(-1, 1)
prho <- (rho + 1) / 2
logit_rho <- log(prho / (1 - prho))
sigma[1,1] <- sd_beta_0 * sd_beta_0
sigma[2,2] <- sd_beta_1 * sd_beta_1
sigma[1,2] <- sd_beta_0 * rho * sd_beta_1
sigma[2,1] <- sigma[1,2]
pre[1:2,1:2] <- inverse(sigma[1:2,1:2])
}
")
data_list <- list(
Nobs = nrow(mydata),
subject = mydata$ID,
N = length(unique(mydata$ID)),
y = mydata$y_it,
x = mydata$x_it
)
jags_file <- textConnection(jags_text)
jags_model <- jags.model(jags_file,
data = data_list,
n.chain = 4)
update(jags_model, 5000)
variables <- c("mu", "phi", "beta_0", "beta_1",
"log_pre", "log_tau_beta_0", "log_tau_beta_1", "logit_rho",
"y_pre", "tau_beta_0", "tau_beta_1", "rho")
post <- coda.samples(jags_model,
variable.names = variables,
n.iter = 25000, thin = 10)
samps <- do.call(rbind, post)
View(samps)
source("posterior_summary.R")
source("posterior_summary.R")
set.seed(123)
Nnum <- 500 # number of level 2 units
Tnum <- 50  # number of level 1 units
beta <- c(0, 0.3)
rho <- 0.3
u_cov <- sqrt(1)*sqrt(0.09)*rho
u_sigma <- matrix(c(1, u_cov, u_cov, 0.09), nrow = 2)
bdata <- mvrnorm(Nnum, mu = beta, Sigma = u_sigma)
bdata <- as.data.frame(bdata)
names(bdata) <- c("mu", "phi")
bdata$ID <- c(1:Nnum)
mydata <- data.frame(matrix(NA, nrow = Nnum*Tnum, ncol = 2))
names(mydata) <- c("ID", "t")
mydata$ID <- rep(1:Nnum, each = Tnum)
mydata$t <- rep(1:Tnum, Nnum)
mydata$e_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 0.1)
mydata$x_it <- rnorm(n = Nnum*Tnum, mean = 0, sd = 1)
mydata <- left_join(mydata, bdata[, c("ID", "mu","phi")], by = "ID")
mydata$y_it <- mydata$mu + mydata$x_it*mydata$phi + mydata$e_it
result <- summarize_posterior(post)
View(result)
max(result$RHAT)
library(("blvmeval"))
library("blvmeval")
raneff_mu_list <- vector("list", Nnum)
raneff_cov_list <- vector("list", Nnum)
for (i in 1:Nnum) {
raneff_mu_list[[i]] <- c(
mean(samps[, paste0("mu[", i, "]")]),
mean(samps[, paste0("phi[", i, "]")])
)
raneff_cov_list[[i]] <- cov(samps[, c(paste0("mu[", i, "]"), paste0("phi[", i, "]"))])
}
View(raneff_mu_list)
View(raneff_cov_list)
# specify the function that computes the log joint probability for each unit
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# conditional likelihood
Nobs <- data$Nobs
Nnum <- data$N
Tnum <- Nobs/Nnum
y_i <- data$y[((i-1)*Tnum+1):(i*Tnum)]
x_i <- data$x[((i-1)*Tnum+1):(i*Tnum)]
predicted_y <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_t_i <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_i <- numeric(Ngrid*Ngrid) # log likelihood for all observations for person i, for each quadrature point
x_i_extended <- rep(x_i, times = Ngrid * Ngrid)
x_i_extended_mat <- matrix(x_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
y_i_extended <- rep(y_i, times = Ngrid * Ngrid)
y_i_extended_mat <- matrix(y_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
# Compute log conditional likelihood for each unit
predicted_y <- nodes[, 1] + nodes[, 2] * x_i_extended_mat
log_con_t_i <- dnorm(y_i_extended_mat, mean = predicted_y, sd = 1/sqrt(samples_s[["y_pre"]]), log = TRUE)
log_con_i <- rowSums(log_con_t_i)
# Compute log prior probability for latent variables (random effects)
raneff_i <- numeric(Ngrid*Ngrid)
sd_mu <- sqrt(1/samples_s[["tau_beta_0"]])
sd_phi <- sqrt(1/samples_s[["tau_beta_1"]])
mean <- c(samples_s[["beta_0"]], samples_s[["beta_1"]])
sigma <- matrix(c(sd_mu^2, sd_mu*samples_s[["rho"]]*sd_phi,
sd_mu*samples_s[["rho"]]*sd_phi, sd_phi^2), nrow = 2)
log_raneff_i <- mvtnorm::dmvnorm(nodes, mean, sigma, log = TRUE)
# Return the log joint probability for each unit
log_raneff_i + log_con_i
}
log_lik_result <- blvmeval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
blvmeval::calc_IC(log_lik_result, 1)
library(blvmeval)
library(bleval)
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/blvmeval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
library(bleval)
log_lik_result <- blvmeval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
# specify the function that computes the log joint probability for each unit
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# conditional likelihood
Nobs <- data$Nobs
Nnum <- data$N
Tnum <- Nobs/Nnum
y_i <- data$y[((i-1)*Tnum+1):(i*Tnum)]
x_i <- data$x[((i-1)*Tnum+1):(i*Tnum)]
predicted_y <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_t_i <- matrix(NA, nrow = Ngrid*Ngrid, ncol = Tnum)
log_con_i <- numeric(Ngrid*Ngrid) # log likelihood for all observations for person i, for each quadrature point
x_i_extended <- rep(x_i, times = Ngrid * Ngrid)
x_i_extended_mat <- matrix(x_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
y_i_extended <- rep(y_i, times = Ngrid * Ngrid)
y_i_extended_mat <- matrix(y_i_extended, nrow = Ngrid * Ngrid, ncol = Tnum, byrow = TRUE)
# Compute log conditional likelihood for each unit
predicted_y <- nodes[, 1] + nodes[, 2] * x_i_extended_mat
log_con_t_i <- dnorm(y_i_extended_mat, mean = predicted_y, sd = 1/sqrt(samples_s[["y_pre"]]), log = TRUE)
log_con_i <- rowSums(log_con_t_i)
# Compute log prior probability for latent variables (random effects)
raneff_i <- numeric(Ngrid*Ngrid)
sd_mu <- sqrt(1/samples_s[["tau_beta_0"]])
sd_phi <- sqrt(1/samples_s[["tau_beta_1"]])
mean <- c(samples_s[["beta_0"]], samples_s[["beta_1"]])
sigma <- matrix(c(sd_mu^2, sd_mu*samples_s[["rho"]]*sd_phi,
sd_mu*samples_s[["rho"]]*sd_phi, sd_phi^2), nrow = 2)
log_raneff_i <- mvtnorm::dmvnorm(nodes, mean, sigma, log = TRUE)
# Return the log joint probability for each unit
log_raneff_i + log_con_i
}
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
# unloadNamespace("bleval")
# remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
library(bleval)
save.image("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval/example/0314.RData")
unloadNamespace("bleval")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
remove.packages("blvmeval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
unloadNamespace("bleval")
remove.packages("bleval", lib = "D:/Software/R/R-4.2.2/library")
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
bleval::calc_IC(log_lik_result, 1)
summary(post)
View(result)
dim(samps)
remove.packages("blvmeval", lib = "D:/Software/R/R-4.2.2/library")
load("0314rmd.RData")
knitr::opts_chunk$set(echo = TRUE)
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
# Create lists to store posterior means and covariance matrices of random effects
raneff_mu_list <- vector("list", Nnum)
raneff_cov_list <- vector("list", Nnum)
for (i in 1:Nnum) {
raneff_mu_list[[i]] <- c(
mean(samps[, paste0("mu[", i, "]")]),
mean(samps[, paste0("phi[", i, "]")])
)
raneff_cov_list[[i]] <- cov(samps[, c(paste0("mu[", i, "]"), paste0("phi[", i, "]"))])
}
log_joint_i <- function(samples_s, data, i, Ngrid, nodes) {
# Extract data for unit i
Nobs <- data$Nobs
Nnum <- data$N
Tnum <- Nobs / Nnum
y_i <- data$y[((i-1)*Tnum+1):(i*Tnum)]
x_i <- data$x[((i-1)*Tnum+1):(i*Tnum)]
# Expand x and y values for quadrature grid
x_i_extended_mat <- matrix(rep(x_i, times = Ngrid * Ngrid), nrow = Ngrid * Ngrid, byrow = TRUE)
y_i_extended_mat <- matrix(rep(y_i, times = Ngrid * Ngrid), nrow = Ngrid * Ngrid, byrow = TRUE)
# Compute log conditional likelihood
predicted_y <- nodes[, 1] + nodes[, 2] * x_i_extended_mat
log_con_t_i <- dnorm(y_i_extended_mat, mean = predicted_y, sd = 1 / sqrt(samples_s[["y_pre"]]), log = TRUE)
log_con_i <- rowSums(log_con_t_i)
# Compute log prior probability for latent variables
sd_mu <- sqrt(1 / samples_s[["tau_beta_0"]])
sd_phi <- sqrt(1 / samples_s[["tau_beta_1"]])
mean <- c(samples_s[["beta_0"]], samples_s[["beta_1"]])
sigma <- matrix(c(sd_mu^2, sd_mu * samples_s[["rho"]] * sd_phi,
sd_mu * samples_s[["rho"]] * sd_phi, sd_phi^2), nrow = 2)
log_raneff_i <- mvtnorm::dmvnorm(nodes, mean, sigma, log = TRUE)
# Return log joint probability
log_raneff_i + log_con_i
}
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
log_lik_result <- bleval::log_lik(samples = samps, data = data_list, Ngrid = 9,
lv_mu = raneff_mu_list, lv_cov = raneff_cov_list,
log_joint_i = log_joint_i)
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
unloadNamespace("bleval")
library(bleval)
bleval::log_lik
install.packages("D:/2_PhD/C_project/P15_marginal likelihood_tutorial/bleval/bleval_0.0.0.9000.tar.gz",
repos = NULL, lib = "D:/Software/R/R-4.2.2/library")
getAnywhere(log_lik)
library(bleval, lib.loc = "D:/Software/R/R-4.2.2/library")
bleval::log_lik
installed.packages()[, c("Package", "LibPath", "Version")]
remove.packages("bleval")
.libPaths("D:/Software/R/R-4.2.2/library")
bleval::log_lik
install.packages("htmltools", lib = "D:/Software/R/R-4.2.2/library")
install.packages("htmltools", lib = "D:/Software/R/R-4.2.2/library")
remove.packages("htmltools", lib = "D:/Software/R/R-4.2.2/library")
remove.packages("htmltools")
remove.packages("htmltools", lib = "C:/Users/xh/AppData/Local/Temp/RtmpCuXqf2/downloaded_packages")
install.packages("htmltools")
install.packages("htmltools")
package_version(htmltools)
package_version("htmltools")
package_version(ggplot2)
package_version("ggplot2")
package_version("mvtnorm")
packageVersion("mvtnorm")
packageVersion("htmltools")
install.packages("htmltools", lib = "D:/Software/R/R-4.2.2/library")
install.packages("htmltools", lib = "D:/Software/R/R-4.2.2/library")
